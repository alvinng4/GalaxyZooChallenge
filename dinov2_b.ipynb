{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Galaxy Zoo - The Galaxy Challenge\n",
    "#### Author: Ching-Yin NG\n",
    "#### Source code and report are available at https://github.com/alvinng4/GalaxyZooChallenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Is the object a smooth galaxy, a galaxy with features/disk or a star? 3 responses\\\n",
    "Q2. Is it edge-on? 2 responses\\\n",
    "Q3. Is there a bar? 2 responses\\\n",
    "Q4. Is there a spiral pattern? 2 responses\\\n",
    "Q5. How prominent is the central bulge? 4 responses\\\n",
    "Q6. Is there anything \"odd\" about the galaxy? 2 responses\\\n",
    "Q7. How round is the smooth galaxy? 3 responses\\\n",
    "Q8. What is the odd feature? 7 responses\\\n",
    "Q9. What shape is the bulge in the edge-on galaxy? 3 responses\\\n",
    "Q10. How tightly wound are the spiral arms? 3 responses\\\n",
    "Q11. How many spiral arms are there? 6 responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import math\n",
    "import pickle\n",
    "import timeit\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE_BEFORE_SCALING = 224\n",
    "TRAIN_SCALING_UPPER = IMAGE_SIZE_BEFORE_SCALING + 64\n",
    "TRAIN_SCALING_LOWER = IMAGE_SIZE_BEFORE_SCALING - 96\n",
    "\n",
    "OUTPUT_NUM_ROTATIONS = 8\n",
    "OUTPUT_REFLECTION_FLAG = True\n",
    "\n",
    "BATCH_SIZE = 105\n",
    "FRACTION_FILES_VALIDATION = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 1\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    # random.seed(seed)\n",
    "    # os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed_everything(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBCLASS_LEN = [3, 2, 2, 2, 4, 2, 3, 7, 3, 3, 6]\n",
    "SUBCLASS_LEN_CUMSUM = np.cumsum(SUBCLASS_LEN)\n",
    "CLASS_LEN = len(SUBCLASS_LEN)\n",
    "\n",
    "FILE_PREFIX = \"dinov2_b\"\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = Path(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = DATA_FOLDER / \"images_training_rev1\"\n",
    "file_list = sorted([str(path) for path in img_path.glob(\"*.jpg\")])\n",
    "print(f\"Number of data: {len(file_list)}\")\n",
    "\n",
    "train_sol_path = DATA_FOLDER / \"training_solutions_rev1.csv\"\n",
    "train_sol = polars.read_csv(train_sol_path)\n",
    "print(\"Some labels: \")\n",
    "print(train_sol.head())\n",
    "\n",
    "soft_labels = train_sol[:, 1:].to_numpy()\n",
    "\n",
    "one_hot_labels = np.argmax(\n",
    "    soft_labels[:, : SUBCLASS_LEN_CUMSUM[0]], axis=1\n",
    ")  # Class one\n",
    "for i in range(1, CLASS_LEN):\n",
    "    one_hot_labels = np.vstack(\n",
    "        (\n",
    "            one_hot_labels,\n",
    "            np.argmax(\n",
    "                soft_labels[:, SUBCLASS_LEN_CUMSUM[i - 1] : SUBCLASS_LEN_CUMSUM[i]],\n",
    "                axis=1,\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "one_hot_labels = one_hot_labels.T\n",
    "print(soft_labels)\n",
    "print(soft_labels.shape)\n",
    "print(one_hot_labels)\n",
    "print(one_hot_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, file_list, labels, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file = self.file_list[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        image = Image.open(file)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "class TransformTrain:\n",
    "    def __init__(self):\n",
    "        self.rng = np.random.default_rng(seed=RANDOM_STATE)\n",
    "        self.random_rotate = transforms.RandomRotation(360)\n",
    "        self.transform_train = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize([224, 224]),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        rotated_img = self.random_rotate(x)\n",
    "        random_crop_size = self.rng.integers(\n",
    "            low=(TRAIN_SCALING_LOWER), high=(TRAIN_SCALING_UPPER)\n",
    "        )\n",
    "        cropped_image = transforms.functional.center_crop(\n",
    "            rotated_img, [random_crop_size, random_crop_size]\n",
    "        )\n",
    "\n",
    "        return self.transform_train(cropped_image)\n",
    "\n",
    "\n",
    "class TransformValid:\n",
    "    def __init__(self):\n",
    "        self.transform_valid = transforms.Compose(\n",
    "            [\n",
    "                transforms.CenterCrop(\n",
    "                    [IMAGE_SIZE_BEFORE_SCALING, IMAGE_SIZE_BEFORE_SCALING]\n",
    "                ),\n",
    "                transforms.Resize([224, 224]),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.transform_valid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FRACTION_FILES_VALIDATION > 0.0:\n",
    "    (\n",
    "        train_file_list,\n",
    "        valid_file_list,\n",
    "        train_soft_labels,\n",
    "        valid_soft_labels,\n",
    "    ) = train_test_split(\n",
    "        file_list,\n",
    "        soft_labels,\n",
    "        test_size=FRACTION_FILES_VALIDATION,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=one_hot_labels[:, 0],\n",
    "    )\n",
    "else:\n",
    "    train_file_list = file_list\n",
    "    train_soft_labels = soft_labels\n",
    "\n",
    "    valid_file_list = []\n",
    "    valid_soft_labels = []\n",
    "\n",
    "transform_train = TransformTrain()\n",
    "train_dataset = ImageDataset(train_file_list, train_soft_labels, transform_train)\n",
    "train_one_hot_labels_class_one = np.argmax(train_soft_labels[:, :3], axis=1)\n",
    "\n",
    "if FRACTION_FILES_VALIDATION > 0.0:\n",
    "    transform_valid = TransformValid()\n",
    "    valid_dataset = ImageDataset(valid_file_list, valid_soft_labels, transform_valid)\n",
    "    valid_one_hot_labels_class_one = np.argmax(valid_soft_labels[:, :3], axis=1)\n",
    "\n",
    "print(f\"Length of training files: {len(train_file_list)}\")\n",
    "print(f\"Length of validation files: {len(valid_file_list)}\")\n",
    "\n",
    "print()\n",
    "print(\"Class 1 distribution: \")\n",
    "print(f\"Training dataset: {Counter(train_one_hot_labels_class_one)}\")\n",
    "if FRACTION_FILES_VALIDATION > 0.0:\n",
    "    print(f\"Validation dataset: {Counter(valid_one_hot_labels_class_one)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data_loader = DataLoader(train_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "img_class_zero = []\n",
    "img_class_one = []\n",
    "img_class_two = []\n",
    "img_per_class = 5\n",
    "\n",
    "iter_data_loader = iter(temp_data_loader)\n",
    "while True:\n",
    "    img_batch, label_batch = next(iter_data_loader)\n",
    "    for i in range(100):\n",
    "        img = img_batch[i]\n",
    "        label = label_batch[i]\n",
    "        one_hot_label = np.argmax(label[:3])\n",
    "\n",
    "        if (len(img_class_zero) < img_per_class) and (one_hot_label == 0):\n",
    "            img_class_zero.append(img)\n",
    "        elif (len(img_class_one) < img_per_class) and (one_hot_label == 1):\n",
    "            img_class_one.append(img)\n",
    "        elif (len(img_class_two) < img_per_class) and (one_hot_label == 2):\n",
    "            img_class_two.append(img)\n",
    "\n",
    "    if (\n",
    "        (len(img_class_zero) >= img_per_class)\n",
    "        and (len(img_class_one) >= img_per_class)\n",
    "        and (len(img_class_two) >= img_per_class)\n",
    "    ):\n",
    "        break\n",
    "\n",
    "fig1 = plt.figure(figsize=(9, 15))\n",
    "for i in range(img_per_class):\n",
    "    img = img_class_zero[i].cpu()\n",
    "    ax = fig1.add_subplot(img_per_class, 3, (i * 3) + 1)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f\"Class 1.1:\", size=15)\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "    img = img_class_one[i].cpu()\n",
    "    ax = fig1.add_subplot(img_per_class, 3, (i * 3) + 2)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f\"Class 1.2:\", size=15)\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "    img = img_class_two[i].cpu()\n",
    "    ax = fig1.add_subplot(img_per_class, 3, (i * 3) + 3)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title(f\"Class 1.3:\", size=15)\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14_reg')\n",
    "\n",
    "model = nn.Sequential(\n",
    "    model,\n",
    "    nn.Linear(768, 37),\n",
    "    nn.Sigmoid(),\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones((4, 3, 224, 224))\n",
    "print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = [[], [], [], []]\n",
    "lr_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    num_epochs,\n",
    "    lr_scheduler,\n",
    "    optimizer,\n",
    "    train_dl,\n",
    "    valid_dl,\n",
    "    batch_size,\n",
    "    hist,\n",
    "    lr_hist,\n",
    "    save_every_n_epochs,\n",
    "):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    previous_epochs = len(hist[0])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start = timeit.default_timer()\n",
    "        model.train()\n",
    "        i = 0\n",
    "        loss_hist_train = 0\n",
    "        rmse_hist_train = 0\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            i += 1\n",
    "            if i % 5 == 0:\n",
    "                print(\n",
    "                    f\"Progress: epoch: {previous_epochs + epoch + 1}/{previous_epochs + num_epochs}, batch: {i}/{len(train_dl)}\",\n",
    "                    end=\"\\r\",\n",
    "                )\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred.float(), y_batch.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_hist_train += loss.item() * y_batch.size(0)\n",
    "            rmse_hist_train += mean_squared_error(\n",
    "                y_true=y_batch.cpu(), y_pred=pred.detach().cpu()\n",
    "            )\n",
    "\n",
    "        loss_hist_train /= len(train_dl.dataset)\n",
    "        rmse_hist_train /= len(train_dl.dataset) / batch_size\n",
    "        rmse_hist_train = math.sqrt(rmse_hist_train)\n",
    "\n",
    "        if FRACTION_FILES_VALIDATION > 0.0:\n",
    "            model.eval()\n",
    "            loss_hist_valid = 0\n",
    "            rmse_hist_valid = 0\n",
    "            with torch.no_grad():\n",
    "                for x_batch, y_batch in valid_dl:\n",
    "                    x_batch = x_batch.to(device)\n",
    "                    y_batch = y_batch.to(device)\n",
    "                    pred = model(x_batch)\n",
    "                    loss = loss_fn(pred.float(), y_batch.float())\n",
    "\n",
    "                    loss_hist_valid += loss.item() * y_batch.size(0)\n",
    "                    rmse_hist_valid += mean_squared_error(\n",
    "                        y_true=y_batch.cpu(), y_pred=pred.detach().cpu()\n",
    "                    )\n",
    "\n",
    "            loss_hist_valid /= len(valid_dl.dataset)\n",
    "            rmse_hist_valid /= len(valid_dl.dataset) / batch_size\n",
    "            rmse_hist_valid = math.sqrt(rmse_hist_valid)\n",
    "        else:\n",
    "            loss_hist_valid = 0.0\n",
    "            rmse_hist_valid = 0.0\n",
    "\n",
    "        end = timeit.default_timer()\n",
    "\n",
    "        print_str = (\n",
    "            f\"Epoch: {previous_epochs + epoch + 1} \"\n",
    "            + f\"train rmse: {rmse_hist_train:.4f} \"\n",
    "            + f\"train loss: {loss_hist_train:.4f} \"\n",
    "            + f\"val rmse: {rmse_hist_valid:.4f} \"\n",
    "            + f\"val loss: {loss_hist_valid:.4f} \"\n",
    "            + f\"lr: {lr_scheduler.get_last_lr()[0]} \"\n",
    "            + f\"Time taken: {end - start:.3f}s\"\n",
    "        )\n",
    "        print(print_str)\n",
    "\n",
    "        if (previous_epochs + epoch + 1) % save_every_n_epochs == 0:\n",
    "            torch.save(\n",
    "                model,\n",
    "                OUTPUT_DIR\n",
    "                / f\"{FILE_PREFIX}_model_epoch{previous_epochs + epoch + 1}.pth\",\n",
    "            )\n",
    "\n",
    "        results = [loss_hist_train, loss_hist_valid, rmse_hist_train, rmse_hist_valid]\n",
    "        for i in range(len(hist)):\n",
    "            hist[i].append(results[i])\n",
    "        lr_hist.append(lr_scheduler.get_last_lr()[0])\n",
    "\n",
    "        lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = (\n",
    "    8  # num_workers must set to zero if the images are already transferred to the GPU\n",
    ")\n",
    "\n",
    "if num_workers == 0:\n",
    "    train_dl = DataLoader(train_dataset, BATCH_SIZE, num_workers=0, shuffle=True)\n",
    "\n",
    "    if FRACTION_FILES_VALIDATION > 0.0:\n",
    "        valid_dl = DataLoader(valid_dataset, BATCH_SIZE, num_workers=0, shuffle=False)\n",
    "    else:\n",
    "        valid_dl = None\n",
    "else:\n",
    "    train_dl = DataLoader(\n",
    "        train_dataset,\n",
    "        BATCH_SIZE,\n",
    "        num_workers=num_workers,\n",
    "        persistent_workers=True,\n",
    "        pin_memory=True,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    if FRACTION_FILES_VALIDATION > 0.0:\n",
    "        valid_dl = DataLoader(\n",
    "            valid_dataset,\n",
    "            BATCH_SIZE,\n",
    "            num_workers=num_workers,\n",
    "            persistent_workers=True,\n",
    "            pin_memory=True,\n",
    "            shuffle=False,\n",
    "        )\n",
    "    else:\n",
    "        valid_dl = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 15\n",
    "save_every_n_epochs = 15\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model,\n",
    "    num_epochs,\n",
    "    lr_scheduler,\n",
    "    optimizer,\n",
    "    train_dl,\n",
    "    valid_dl,\n",
    "    BATCH_SIZE,\n",
    "    hist,\n",
    "    lr_hist,\n",
    "    save_every_n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_arr = np.arange(len(hist[0])) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "ax.plot(x_arr, hist[0], \"-o\", label=\"Train loss\")\n",
    "if FRACTION_FILES_VALIDATION > 0.0:\n",
    "    ax.plot(x_arr, hist[1], \"--<\", label=\"Validation loss\")\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel(\"Epoch\", size=15)\n",
    "ax.set_ylabel(\"Loss\", size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "ax.plot(x_arr, hist[2], \"-o\", label=\"Train RMSE\")\n",
    "if FRACTION_FILES_VALIDATION > 0.0:\n",
    "    ax.plot(x_arr, hist[3], \"--<\", label=\"Validation RMSE\")\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel(\"Epoch\", size=15)\n",
    "ax.set_ylabel(\"RMSE\", size=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "ax.plot(x_arr, lr_hist, \"-o\", label=\"lr rate\")\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel(\"Epoch\", size=15)\n",
    "ax.set_ylabel(\"learning rate\", size=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / f\"{FILE_PREFIX}_lr{learning_rate}.png\")\n",
    "plt.show()\n",
    "\n",
    "with open(OUTPUT_DIR / f\"{FILE_PREFIX}_hist.pkl\", \"wb\") as file:\n",
    "    pickle.dump(hist, file)\n",
    "\n",
    "with open(OUTPUT_DIR / f\"{FILE_PREFIX}_lr_hist.pkl\", \"wb\") as file:\n",
    "    pickle.dump(lr_hist, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_img_path = DATA_FOLDER / \"images_test_rev1\"\n",
    "final_test_file_list = sorted([str(path) for path in final_test_img_path.glob(\"*.jpg\")])\n",
    "print(f\"Number of test files: {len(final_test_file_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalTestImageDataset(Dataset):\n",
    "    def __init__(self, file_list, transform=None):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file = self.file_list[index]\n",
    "        image = Image.open(file)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        gxy_id = Path(file).stem\n",
    "\n",
    "        return image, gxy_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedRotation:\n",
    "    def __init__(self, angle):\n",
    "        self.angle = angle\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return transforms.functional.rotate(img, self.angle)\n",
    "\n",
    "\n",
    "class HorizontalFlip:\n",
    "    def __call__(self, img):\n",
    "        return transforms.functional.hflip(img)\n",
    "\n",
    "\n",
    "class Identity:\n",
    "    def __call__(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformOutput:\n",
    "    def __init__(self):\n",
    "        fixed_rotates = [\n",
    "            FixedRotation((360.0 / OUTPUT_NUM_ROTATIONS) * i)\n",
    "            for i in range(OUTPUT_NUM_ROTATIONS)\n",
    "        ]\n",
    "        hflip = HorizontalFlip()\n",
    "        identity = Identity()\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.CenterCrop([IMAGE_SIZE_BEFORE_SCALING, IMAGE_SIZE_BEFORE_SCALING]),\n",
    "                transforms.Resize([224, 224]),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if OUTPUT_REFLECTION_FLAG is True:\n",
    "            all_combinations = list(itertools.product(fixed_rotates, [hflip, identity]))\n",
    "        else:\n",
    "            all_combinations = list(itertools.product(fixed_rotates))\n",
    "        self.all_transforms = [\n",
    "            transforms.Compose([*comb, transform]) for comb in all_combinations\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_files = 0\n",
    "for transform in TransformOutput().all_transforms:\n",
    "    final_test_dataset = FinalTestImageDataset(final_test_file_list, transform)\n",
    "    final_test_dl = DataLoader(\n",
    "        final_test_dataset,\n",
    "        num_workers=0,\n",
    "        persistent_workers=False,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    file_name = f\"submission{int(num_output_files)}.csv\"\n",
    "    with open(file_name, \"w\", newline=\"\") as submission_file:\n",
    "        writer = csv.writer(submission_file)\n",
    "        writer.writerow(\n",
    "            [\n",
    "                \"GalaxyID\",\n",
    "                \"Class1.1\",\n",
    "                \"Class1.2\",\n",
    "                \"Class1.3\",\n",
    "                \"Class2.1\",\n",
    "                \"Class2.2\",\n",
    "                \"Class3.1\",\n",
    "                \"Class3.2\",\n",
    "                \"Class4.1\",\n",
    "                \"Class4.2\",\n",
    "                \"Class5.1\",\n",
    "                \"Class5.2\",\n",
    "                \"Class5.3\",\n",
    "                \"Class5.4\",\n",
    "                \"Class6.1\",\n",
    "                \"Class6.2\",\n",
    "                \"Class7.1\",\n",
    "                \"Class7.2\",\n",
    "                \"Class7.3\",\n",
    "                \"Class8.1\",\n",
    "                \"Class8.2\",\n",
    "                \"Class8.3\",\n",
    "                \"Class8.4\",\n",
    "                \"Class8.5\",\n",
    "                \"Class8.6\",\n",
    "                \"Class8.7\",\n",
    "                \"Class9.1\",\n",
    "                \"Class9.2\",\n",
    "                \"Class9.3\",\n",
    "                \"Class10.1\",\n",
    "                \"Class10.2\",\n",
    "                \"Class10.3\",\n",
    "                \"Class11.1\",\n",
    "                \"Class11.2\",\n",
    "                \"Class11.3\",\n",
    "                \"Class11.4\",\n",
    "                \"Class11.5\",\n",
    "                \"Class11.6\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(\"Getting test results from model...\")\n",
    "        model.eval()\n",
    "        all_preds_soft_labels = np.zeros(\n",
    "            (len(final_test_dataset), SUBCLASS_LEN_CUMSUM[-1])\n",
    "        )\n",
    "        gxy_ids = np.zeros((len(final_test_dataset),))\n",
    "        i = 0\n",
    "        with torch.no_grad():\n",
    "            for img_batch, gxy_id_batch in final_test_dl:\n",
    "                print(f\"Progress: {i + 1} / {len(all_preds_soft_labels)}\", end=\"\\r\")\n",
    "                img_batch = img_batch.to(device)\n",
    "                pred = model(img_batch)\n",
    "                pred_soft_labels = pred.cpu().numpy()\n",
    "\n",
    "                if len(pred_soft_labels) == BATCH_SIZE:\n",
    "                    all_preds_soft_labels[i : (i + BATCH_SIZE)] = pred_soft_labels\n",
    "                    gxy_ids[i : (i + BATCH_SIZE)] = gxy_id_batch\n",
    "                    i += BATCH_SIZE\n",
    "                else:\n",
    "                    all_preds_soft_labels[i:] = pred_soft_labels\n",
    "                    gxy_ids[i:] = gxy_id_batch\n",
    "                    i += len(pred_soft_labels)\n",
    "                    break\n",
    "\n",
    "        print()\n",
    "        print(\"Writing test results to submission file...\")\n",
    "        for i in range(len(all_preds_soft_labels)):\n",
    "            print(f\"Progress: {i + 1} / {len(all_preds_soft_labels)}\", end=\"\\r\")\n",
    "            output_list = [int(gxy_ids[i])] + all_preds_soft_labels[i].tolist()\n",
    "            writer.writerow(output_list)\n",
    "\n",
    "        print()\n",
    "        print(\"Done!\")\n",
    "        num_output_files += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Averaging outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_averaging(file_list):\n",
    "    n_files = len(file_list)\n",
    "    avg_df = pd.read_csv(file_list[0])\n",
    "    first_column = avg_df[[\"GalaxyID\"]].copy()\n",
    "    for i in range(1, n_files):\n",
    "        avg_df += pd.read_csv(file_list[i])\n",
    "    avg_df /= n_files\n",
    "    avg_df = avg_df.drop(columns=[\"GalaxyID\"])\n",
    "    avg_df = pd.concat([first_column, avg_df], axis=1)\n",
    "    avg_df.to_csv(f\"submission.csv\", index=False)\n",
    "\n",
    "\n",
    "file_list = [f\"submission{int(i)}.csv\" for i in range(num_output_files)]\n",
    "simple_averaging(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
